{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kR0SKBDbaOqR"
      },
      "source": [
        "# CS5670 Project 5B\n",
        "\n",
        "In this problem set, you will train your own diffusion model on the MNIST dataset. Youâ€™ll build and train UNet-based diffusion models, gaining hands-on experience with both unconditional and class-conditioned generation.\n",
        "\n",
        "Please refer to the [Project 5B instructions page](https://www.cs.cornell.edu/courses/cs5670/2025sp/projects/5_project/partB.html) for detailed descriptions of each task and submission instructions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ryMrLOORbWLz"
      },
      "source": [
        "## Setup environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lX3XpcGSXBIs"
      },
      "outputs": [],
      "source": [
        "# We recommend using these utils.\n",
        "# https://google.github.io/mediapy/mediapy.html\n",
        "# https://einops.rocks/\n",
        "!pip install mediapy einops --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VdFQ6c9-Pm4Y"
      },
      "outputs": [],
      "source": [
        "# Import essential modules. Feel free to add whatever you need.\n",
        "import matplotlib.pyplot as plt\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision.transforms import ToTensor\n",
        "import dataclasses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZZZziMrxiIk"
      },
      "source": [
        "# Part 1: Training a Single-step Denoising UNet\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Deliverables\n",
        "In summary, your deliverables should include the following for this problem:\n",
        "\n",
        "1.   A visualization of different noising process over $\\sigma = [0.0, 0.25, 0.5, 0.75, 1.0]$ (see Figure 3 on the [instruction page](https://www.cs.cornell.edu/courses/cs5670/2025sp/projects/5_project/partB.html)).\n",
        "2.   A training loss curve plot every few iterations during the whole training process (see Figure 4).\n",
        "3.   Sample results on the test set after the first and the 5-th epoch (staff solution takes ~7 minutes for 5 epochs on a Colab T4 GPU). (see Figures 5 and 6)\n",
        "4.   Sample results on the test set with out-of-distribution noise levels after the model is trained. Keep the same image and vary $\\sigma = [0.0, 0.25, 0.5, 0.75, 1.0, 1.0]$ (see Figure 7).\n",
        "\n",
        "### Hint\n",
        "\n",
        "Since training can take a while, we strongly recommend that you checkpoint your model every epoch onto your personal Google Drive. This is because Colab notebooks aren't persistent such that if you are idle for a while, you will lose connection and your training progress. This consists of:\n",
        "\n",
        "- Google Drive mounting.\n",
        "- Epoch-wise model & optimizer checkpointing.\n",
        "- Model & optimizer resuming from checkpoints."
      ],
      "metadata": {
        "id": "29D66XdGRfjN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1 Implementing the UNet"
      ],
      "metadata": {
        "id": "AFs3BR8zM_FD"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dokvxybn_DwK"
      },
      "source": [
        "### Implementing Simple and Composed Ops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fhpEzgwCJqbW"
      },
      "outputs": [],
      "source": [
        "class Conv(nn.Module):\n",
        "    def __init__(self, in_channels: int, out_channels: int):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        raise NotImplementedError()\n",
        "\n",
        "\n",
        "class DownConv(nn.Module):\n",
        "    def __init__(self, in_channels: int, out_channels: int):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        raise NotImplementedError()\n",
        "\n",
        "\n",
        "class UpConv(nn.Module):\n",
        "    def __init__(self, in_channels: int, out_channels: int):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        raise NotImplementedError()\n",
        "\n",
        "\n",
        "class Flatten(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        raise NotImplementedError()\n",
        "\n",
        "\n",
        "class Unflatten(nn.Module):\n",
        "    def __init__(self, in_channels: int):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        raise NotImplementedError()\n",
        "\n",
        "\n",
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, in_channels: int, out_channels: int):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        raise NotImplementedError()\n",
        "\n",
        "\n",
        "class DownBlock(nn.Module):\n",
        "    def __init__(self, in_channels: int, out_channels: int):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        raise NotImplementedError()\n",
        "\n",
        "\n",
        "class UpBlock(nn.Module):\n",
        "    def __init__(self, in_channels: int, out_channels: int):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        raise NotImplementedError()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Implementing Unconditional UNet"
      ],
      "metadata": {
        "id": "tsntLNl8PkdG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "94h1Q3BxN0ha"
      },
      "outputs": [],
      "source": [
        "class UnconditionalUNet(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_channels: int,\n",
        "        num_hiddens: int,\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        assert x.shape[-2:] == (28, 28), \"Expect input shape to be (28, 28).\"\n",
        "        raise NotImplementedError()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2 Using the UNet to Train a Denoiser\n",
        "In this part, you will train your UNet to perform single-step denoising on MNIST images. You will define your configuration, prepare data, implement training, and visualize results."
      ],
      "metadata": {
        "id": "Brq_35sqNHR0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2.1 Training"
      ],
      "metadata": {
        "id": "DfGLzd52NNIu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Configuration and setup\n",
        "# Define your configuration using dataclass\n",
        "# Include: device (e.g., \"cuda\"), data_dir, batch_size, num_epochs, lr, num_hiddens\n",
        "# === CODE TODO BEGIN ===\n",
        "@dataclasses.dataclass\n",
        "class SingleStepConfig(object):\n",
        "    device: str = None  # TODO\n",
        "    data_dir: str = None  # TODO\n",
        "    batch_size: int = None  # TODO\n",
        "    num_epochs: int = None  # TODO\n",
        "    lr: float = None  # TODO\n",
        "    num_hiddens: int = None  # TODO\n",
        "# === CODE TODO END ===\n",
        "\n",
        "# Set random seeds for reproducibility using random, numpy, and torch\n",
        "def seed_everything(seed: int):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "seed_everything(0)\n",
        "cfg = SingleStepConfig()"
      ],
      "metadata": {
        "id": "kN7Ofl_i7IYd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Load dataset and initialize model/optimizer\n",
        "# === CODE TODO BEGIN ===\n",
        "# Load the MNIST dataset (from torchvision.datasets)\n",
        "# Prepare DataLoader with shuffling for training and no shuffling for testing\n",
        "train_dataset = None  # TODO\n",
        "test_dataset = None  # TODO\n",
        "\n",
        "train_loader = None  # TODO\n",
        "test_loader = None  # TODO\n",
        "\n",
        "# Instantiate your UnconditionalUNet model (from 1.1) and move it to cfg.device\n",
        "model = None  # TODO: Replace with model definition\n",
        "\n",
        "# Define the Adam optimizer\n",
        "optimizer = None  # TODO: Replace with optimizer definition\n",
        "# === CODE TODO END ==="
      ],
      "metadata": {
        "id": "3yrZUGGa7Sod"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Deliverable 1-1\n",
        "# A visualization of different noising process over sigma = [0.0, 0.25, 0.5, 0.75, 1.0].\n",
        "# Hint: you may need to reshape or arrange the image tensors,\n",
        "# and use media.show_images to display results\n",
        "\n",
        "# === CODE TODO BEGIN ===\n",
        "\n",
        "\n",
        "\n",
        "# === CODE TODO END ==="
      ],
      "metadata": {
        "id": "-eWb-jNs8mEY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Training loop\n",
        "# Assumes you have:\n",
        "# - model: your UNet denoiser\n",
        "# - optimizer: Adam optimizer\n",
        "# - train_loader: batches of MNIST images\n",
        "# - device: \"cuda\" or \"cpu\"\n",
        "# - loss_fn: a loss function\n",
        "# Impltement the training loop to train your model for several epochs\n",
        "# Remember to use your configuration, e.g. cfg.batch_size and cfg.device\n",
        "# === CODE TODO BEGIN ===\n",
        "\n",
        "\n",
        "\n",
        "# === CODE TODO END ==="
      ],
      "metadata": {
        "id": "ekP8bMnR75NH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Deliverable 1-2\n",
        "# A training loss curve plot every few iterations during the whole training process.\n",
        "# === CODE TODO BEGIN ===\n",
        "\n",
        "\n",
        "\n",
        "# === CODE TODO END ==="
      ],
      "metadata": {
        "id": "wVbdSC7jAymc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Deliverable 1-3\n",
        "# Sample results on the test set after the first and the 5-th epoch\n",
        "# Hint: You can either visualize results immediately during training (recommended for easier comparison),\n",
        "#  or Store outputs and visualize later after training.\n",
        "# === CODE TODO BEGIN ===\n",
        "\n",
        "\n",
        "\n",
        "# === CODE TODO END ==="
      ],
      "metadata": {
        "id": "a_B74zcmAyDt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2.2 Out-of-Distribution Testing"
      ],
      "metadata": {
        "id": "9NK1L-fcNSEa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Deliverable 1-4\n",
        "# Sample results on the test set with out-of-distribution noise levels after the model is trained.\n",
        "# Keep the same image and vary \\sigma = [0.0, 0.25, 0.5, 0.75, 1.0, 1.0].\n",
        "# === CODE TODO BEGIN ===\n",
        "\n",
        "\n",
        "\n",
        "# === CODE TODO END ==="
      ],
      "metadata": {
        "id": "gXWYtPOg9cJN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ObcO_jUamVE"
      },
      "source": [
        "# Part 2: Training a Diffusion Model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Deliverables for Time-conditioned UNet\n",
        "- A training loss curve plot for the time-conditioned UNet over the whole training process (figure 10).\n",
        "- Sampling results for the time-conditioned UNet for 5 and 20 epochs.\n",
        "Note: providing a gif is optional."
      ],
      "metadata": {
        "id": "dxP84f40XRps"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMI3IMkjayxQ"
      },
      "source": [
        "## 2.1 Implementing a Time-conditioned UNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fkchbyYkzAvV"
      },
      "outputs": [],
      "source": [
        "class FCBlock(nn.Module):\n",
        "    def __init__(self, in_channels: int, out_channels: int):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        raise NotImplementedError()\n",
        "\n",
        "\n",
        "class TimeConditionalUNet(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_channels: int,\n",
        "        num_classes: int,\n",
        "        num_hiddens: int,\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        x: torch.Tensor,\n",
        "        t: torch.Tensor,\n",
        "    ) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x: (N, C, H, W) input tensor.\n",
        "            t: (N,) normalized time tensor.\n",
        "\n",
        "        Returns:\n",
        "            (N, C, H, W) output tensor.\n",
        "        \"\"\"\n",
        "        assert x.shape[-2:] == (28, 28), \"Expect input shape to be (28, 28).\"\n",
        "        raise NotImplementedError()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2 Training the UNet and 2.3 Sampling from the UNet"
      ],
      "metadata": {
        "id": "9qXa2-5aOFUB"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nyxOM-RbZnC"
      },
      "source": [
        "### Implementing DDPM Forward and Inverse Process for Time-conditioned Denoising"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yIvMw63T6JkE"
      },
      "outputs": [],
      "source": [
        "def ddpm_schedule(beta1: float, beta2: float, num_ts: int) -> dict:\n",
        "    \"\"\"Constants for DDPM training and sampling.\n",
        "\n",
        "    Arguments:\n",
        "        beta1: float, starting beta value.\n",
        "        beta2: float, ending beta value.\n",
        "        num_ts: int, number of timesteps.\n",
        "\n",
        "    Returns:\n",
        "        dict with keys:\n",
        "            betas: linear schedule of betas from beta1 to beta2.\n",
        "            alphas: 1 - betas.\n",
        "            alpha_bars: cumulative product of alphas.\n",
        "    \"\"\"\n",
        "    assert beta1 < beta2 < 1.0, \"Expect beta1 < beta2 < 1.0.\"\n",
        "    raise NotImplementedError()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hfvtHEFf_7Q3"
      },
      "outputs": [],
      "source": [
        "def ddpm_forward(\n",
        "    unet: TimeConditionalUNet,\n",
        "    ddpm_schedule: dict,\n",
        "    x_0: torch.Tensor,\n",
        "    num_ts: int,\n",
        ") -> torch.Tensor:\n",
        "    \"\"\"Algorithm 1 of the DDPM paper.\n",
        "\n",
        "    Args:\n",
        "        unet: TimeConditionalUNet\n",
        "        ddpm_schedule: dict\n",
        "        x_0: (N, C, H, W) input tensor.\n",
        "        num_ts: int, number of timesteps.\n",
        "    Returns:\n",
        "        (,) diffusion loss.\n",
        "    \"\"\"\n",
        "    unet.train()\n",
        "    # YOUR CODE HERE.\n",
        "    raise NotImplementedError()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BNE8-455IDm3"
      },
      "outputs": [],
      "source": [
        "@torch.inference_mode()\n",
        "def ddpm_sample(\n",
        "    unet: TimeConditionalUNet,\n",
        "    ddpm_schedule: dict,\n",
        "    img_wh: tuple[int, int],\n",
        "    num_ts: int,\n",
        "    seed: int = 0,\n",
        ") -> torch.Tensor:\n",
        "    \"\"\"Algorithm 2 of the DDPM paper with classifier-free guidance.\n",
        "\n",
        "    Args:\n",
        "        unet: TimeConditionalUNet\n",
        "        ddpm_schedule: dict\n",
        "        img_wh: (H, W) output image width and height.\n",
        "        num_ts: int, number of timesteps.\n",
        "        seed: int, random seed.\n",
        "\n",
        "    Returns:\n",
        "        (N, C, H, W) final sample.\n",
        "    \"\"\"\n",
        "    unet.eval()\n",
        "    # YOUR CODE HERE.\n",
        "    raise NotImplementedError()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G_hVifFyw20j"
      },
      "outputs": [],
      "source": [
        "class DDPM(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        unet: TimeConditionalUNet,\n",
        "        betas: tuple[float, float] = (1e-4, 0.02),\n",
        "        num_ts: int = 300,\n",
        "        p_uncond: float = 0.1,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.unet = unet\n",
        "        self.betas = betas\n",
        "        self.num_ts = num_ts\n",
        "        self.p_uncond = p_uncond\n",
        "        self.ddpm_schedule = ddpm_schedule(betas[0], betas[1], num_ts)\n",
        "\n",
        "        for k, v in ddpm_schedule(betas[0], betas[1], num_ts).items():\n",
        "            self.register_buffer(k, v, persistent=False)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x: (N, C, H, W) input tensor.\n",
        "\n",
        "        Returns:\n",
        "            (,) diffusion loss.\n",
        "        \"\"\"\n",
        "        return ddpm_forward(\n",
        "            self.unet, self.ddpm_schedule, x, self.num_ts\n",
        "        )\n",
        "\n",
        "    @torch.inference_mode()\n",
        "    def sample(\n",
        "        self,\n",
        "        img_wh: tuple[int, int],\n",
        "        seed: int = 0,\n",
        "    ):\n",
        "        return ddpm_sample(\n",
        "            self.unet, self.ddpm_schedule, img_wh, self.num_ts, seed\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training"
      ],
      "metadata": {
        "id": "8EctBcpc3TWv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Configuration and setup\n",
        "# Define your configuration class for DDPM\n",
        "# Include: device, data_dir, work_dir, num_hiddens, num_ts, p_uncond, betas, num_epochs, batch_size, lr, lr_decay\n",
        "\n",
        "# === CODE TODO BEGIN ===\n",
        "@dataclasses.dataclass\n",
        "class DDPMConfig(object):\n",
        "    device: str = None  # TODO\n",
        "    data_dir: str = None  # TODO\n",
        "    work_dir: str = None  # TODO\n",
        "    num_hiddens: int = None  # TODO\n",
        "    num_ts: int = None  # TODO  # number of diffusion steps\n",
        "    p_uncond: float = None  # TODO  # classifier-free guidance dropout probability\n",
        "    betas: tuple[float, float] = None  # TODO  # linear noise schedule\n",
        "    num_epochs: int = None  # TODO\n",
        "    batch_size: int = None  # TODO\n",
        "    lr: float = None  # TODO\n",
        "    lr_decay: float = None  # TODO\n",
        "# === CODE TODO END ===\n",
        "\n",
        "# Set random seed\n",
        "seed_everything(0)\n",
        "# Create config instance\n",
        "cfg = DDPMConfig()"
      ],
      "metadata": {
        "id": "DWytvaJLbVVo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Load dataset and initialize model/optimizer/schedule\n",
        "# === CODE TODO BEGIN ===\n",
        "# Load the MNIST dataset (from torchvision.datasets)\n",
        "# Prepare DataLoader with shuffling for training and no shuffling for testing\n",
        "train_dataset = None  # TODO\n",
        "test_dataset = None  # TODO\n",
        "\n",
        "train_loader = None  # TODO\n",
        "test_loader = None  # TODO\n",
        "\n",
        "# Create the beta schedule for DDPM (use ddpm_schedule helper)\n",
        "schedule = None  # TODO\n",
        "\n",
        "# Instantiate your TimeConditionalUNet model (from 2.1) and move it to cfg.device\n",
        "model = None  # TODO\n",
        "\n",
        "# Create optimizer (Adam) and learning rate scheduler (ExponentialLR)\n",
        "optimizer = None  # TODO\n",
        "scheduler = None  # TODO\n",
        "# === CODE TODO END ==="
      ],
      "metadata": {
        "id": "WQqgrPembWpV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Training loop\n",
        "# Assumes you have:\n",
        "# - model: a Conditional UNet (time- and class-conditioned) on cfg.device\n",
        "# - optimizer: Adam optimizer with learning rate cfg.lr\n",
        "# - scheduler: ExponentialLR to decay learning rate over cfg.num_epochs\n",
        "# - train_loader: batches of MNIST images and labels\n",
        "# - schedule: output of ddpm_schedule\n",
        "# - cfg: your DDPMConfig instance containing training parameters\n",
        "# - device: \"cuda\" or \"cpu\"\n",
        "# Impltement the training loop to train your model for several epochs\n",
        "# === CODE TODO BEGIN ===\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# === CODE TODO END ==="
      ],
      "metadata": {
        "id": "wT3OatLSGajx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Deliverable 2-1\n",
        "# A training loss curve plot for the time-conditioned UNet over the whole training process.\n",
        "# === CODE TODO BEGIN ===\n",
        "\n",
        "\n",
        "\n",
        "# === CODE TODO END ==="
      ],
      "metadata": {
        "id": "7EVCmVcVIE_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Deliverable 2-2\n",
        "# Sampling results for the time-conditioned UNet for 5 and 20 epochs. Note: providing a gif is optional.\n",
        "# Hint: You can either visualize results immediately during training (recommended for easier comparison),\n",
        "#  or Store outputs and visualize later after training.\n",
        "# === CODE TODO BEGIN ===\n",
        "\n",
        "\n",
        "\n",
        "# === CODE TODO END ==="
      ],
      "metadata": {
        "id": "Z5J6G-jcIH7S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Deliverables for Class-conditioned UNet\n",
        "- A training loss curve plot for the class-conditioned UNet over the whole training process.\n",
        "- Sampling results for the class-conditioned UNet for 5 and 20 epochs. Generate 4 instances of each digit as shown above.\n",
        "Note: providing a gif is optional."
      ],
      "metadata": {
        "id": "tT-Y2Q0WXZBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.4 Implementing class-conditioned UNet"
      ],
      "metadata": {
        "id": "uW2FBjpn8CTZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ClassConditionalUNet(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_channels: int,\n",
        "        num_classes: int,\n",
        "        num_hiddens: int,\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        x: torch.Tensor,\n",
        "        c: torch.Tensor,\n",
        "        t: torch.Tensor,\n",
        "        mask: torch.Tensor | None = None,\n",
        "    ) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x: (N, C, H, W) input tensor.\n",
        "            c: (N,) int64 condition tensor.\n",
        "            t: (N,) normalized time tensor.\n",
        "            mask: (N,) mask tensor. If not None, mask out condition when mask == 0.\n",
        "\n",
        "        Returns:\n",
        "            (N, C, H, W) output tensor.\n",
        "        \"\"\"\n",
        "        assert x.shape[-2:] == (28, 28), \"Expect input shape to be (28, 28).\"\n",
        "        raise NotImplementedError()"
      ],
      "metadata": {
        "id": "vAXZYlOt8Rzy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.5 Training and Sampling from the Class-Conditioned UNet"
      ],
      "metadata": {
        "id": "xU2lJgTCN-fn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ddpm_forward(\n",
        "    unet: ClassConditionalUNet,\n",
        "    ddpm_schedule: dict,\n",
        "    x_0: torch.Tensor,\n",
        "    c: torch.Tensor,\n",
        "    p_uncond: float,\n",
        "    num_ts: int,\n",
        ") -> torch.Tensor:\n",
        "    \"\"\"Algorithm 1 of the DDPM paper.\n",
        "\n",
        "    Args:\n",
        "        unet: ClassConditionalUNet\n",
        "        ddpm_schedule: dict\n",
        "        x_0: (N, C, H, W) input tensor.\n",
        "        c: (N,) int64 condition tensor.\n",
        "        p_uncond: float, probability of unconditioning the condition.\n",
        "        num_ts: int, number of timesteps.\n",
        "\n",
        "    Returns:\n",
        "        (,) diffusion loss.\n",
        "    \"\"\"\n",
        "    unet.train()\n",
        "    # YOUR CODE HERE.\n",
        "    raise NotImplementedError()"
      ],
      "metadata": {
        "id": "NobmVh4U8BRP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.inference_mode()\n",
        "def ddpm_sample(\n",
        "    unet: ClassConditionalUNet,\n",
        "    ddpm_schedule: dict,\n",
        "    c: torch.Tensor,\n",
        "    img_wh: tuple[int, int],\n",
        "    num_ts: int,\n",
        "    guidance_scale: float = 5.0,\n",
        "    seed: int = 0,\n",
        ") -> torch.Tensor:\n",
        "    \"\"\"Algorithm 2 of the DDPM paper with classifier-free guidance.\n",
        "\n",
        "    Args:\n",
        "        unet: ClassConditionalUNet\n",
        "        ddpm_schedule: dict\n",
        "        c: (N,) int64 condition tensor. Only for class-conditional\n",
        "        img_wh: (H, W) output image width and height.\n",
        "        num_ts: int, number of timesteps.\n",
        "        guidance_scale: float, CFG scale.\n",
        "        seed: int, random seed.\n",
        "\n",
        "    Returns:\n",
        "        (N, C, H, W) final sample.\n",
        "        (N, T_animation, C, H, W) caches.\n",
        "    \"\"\"\n",
        "    unet.eval()\n",
        "    # YOUR CODE HERE.\n",
        "    raise NotImplementedError()"
      ],
      "metadata": {
        "id": "rMW5YeCi8cqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DDPM(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        unet: ClassConditionalUNet,\n",
        "        betas: tuple[float, float] = (1e-4, 0.02),\n",
        "        num_ts: int = 300,\n",
        "        p_uncond: float = 0.1,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.unet = unet\n",
        "        self.betas = betas\n",
        "        self.num_ts = num_ts\n",
        "        self.p_uncond = p_uncond\n",
        "        self.ddpm_schedule = ddpm_schedule(betas[0], betas[1], num_ts)\n",
        "\n",
        "    def forward(self, x: torch.Tensor, c: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x: (N, C, H, W) input tensor.\n",
        "            c: (N,) int64 condition tensor.\n",
        "\n",
        "        Returns:\n",
        "            (,) diffusion loss.\n",
        "        \"\"\"\n",
        "        return ddpm_forward(\n",
        "            self.unet, self.ddpm_schedule, x, c, self.p_uncond, self.num_ts\n",
        "        )\n",
        "\n",
        "    @torch.inference_mode()\n",
        "    def sample(\n",
        "        self,\n",
        "        c: torch.Tensor,\n",
        "        img_wh: tuple[int, int],\n",
        "        guidance_scale: float = 5.0,\n",
        "        seed: int = 0,\n",
        "    ):\n",
        "        return ddpm_sample(\n",
        "            self.unet, self.ddpm_schedule, c, img_wh, self.num_ts, guidance_scale, seed\n",
        "        )"
      ],
      "metadata": {
        "id": "gdQFWwIt8mXh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training"
      ],
      "metadata": {
        "id": "DW-ATSqR4GbQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Configuration and setup\n",
        "# Define your configuration class for DDPM\n",
        "# Include: device, data_dir, work_dir, num_hiddens, num_ts, p_uncond, betas, num_epochs, batch_size, lr, lr_decay\n",
        "\n",
        "# === CODE TODO BEGIN ===\n",
        "@dataclasses.dataclass\n",
        "class DDPMConfig(object):\n",
        "    device: str = None  # TODO\n",
        "    data_dir: str = None  # TODO\n",
        "    work_dir: str = None  # TODO\n",
        "    num_hiddens: int = None  # TODO\n",
        "    num_ts: int = None  # TODO  # number of diffusion steps\n",
        "    p_uncond: float = None  # TODO  # classifier-free guidance dropout probability\n",
        "    betas: tuple[float, float] = None  # TODO  # linear noise schedule\n",
        "    num_epochs: int = None  # TODO\n",
        "    batch_size: int = None  # TODO\n",
        "    lr: float = None  # TODO\n",
        "    lr_decay: float = None  # TODO\n",
        "# === CODE TODO END ===\n",
        "\n",
        "# Set random seed\n",
        "seed_everything(0)\n",
        "# Create config instance\n",
        "cfg = DDPMConfig()"
      ],
      "metadata": {
        "id": "19RvHcJo4WBD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Load dataset and initialize model/optimizer/schedule\n",
        "# === CODE TODO BEGIN ===\n",
        "# Load the MNIST dataset (from torchvision.datasets)\n",
        "# Prepare DataLoader with shuffling for training and no shuffling for testing\n",
        "train_dataset = None  # TODO\n",
        "test_dataset = None  # TODO\n",
        "\n",
        "train_loader = None  # TODO\n",
        "test_loader = None  # TODO\n",
        "\n",
        "# Create the beta schedule for DDPM (use ddpm_schedule helper)\n",
        "schedule = None  # TODO\n",
        "\n",
        "# Instantiate your ClassConditionalUNet model (from 2.1) and move it to cfg.device\n",
        "model = None  # TODO\n",
        "\n",
        "# Create optimizer (Adam) and learning rate scheduler (ExponentialLR)\n",
        "optimizer = None  # TODO\n",
        "scheduler = None  # TODO\n",
        "# === CODE TODO END ==="
      ],
      "metadata": {
        "id": "oAIu9DOpJa61"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Training loop\n",
        "# Assumes you have:\n",
        "# - model: a Conditional UNet (time- and class-conditioned) on cfg.device\n",
        "# - optimizer: Adam optimizer with learning rate cfg.lr\n",
        "# - scheduler: ExponentialLR to decay learning rate over cfg.num_epochs\n",
        "# - train_loader: batches of MNIST images and labels\n",
        "# - schedule: output of ddpm_schedule\n",
        "# - cfg: your DDPMConfig instance containing training parameters\n",
        "# - device: \"cuda\" or \"cpu\"\n",
        "# Impltement the training loop to train your model for several epochs\n",
        "# === CODE TODO BEGIN ===\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# === CODE TODO END ==="
      ],
      "metadata": {
        "id": "GO5DWgBDJccE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Deliverable 2-3\n",
        "# A training loss curve plot for the class-conditioned UNet over the whole training process.\n",
        "# === CODE TODO BEGIN ===\n",
        "\n",
        "\n",
        "\n",
        "# === CODE TODO END ==="
      ],
      "metadata": {
        "id": "9B-mPknHJDUM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Deliverable 2-4\n",
        "# Sampling results for the class-conditioned UNet for 5 and 20 epochs.\n",
        "# Generate 4 instances of each digit. Note: providing a gif is optional.\n",
        "# Hint: You can either visualize results immediately during training (recommended for easier comparison),\n",
        "#  or Store outputs and visualize later after training.\n",
        "# === CODE TODO BEGIN ===\n",
        "\n",
        "\n",
        "\n",
        "# === CODE TODO END ==="
      ],
      "metadata": {
        "id": "xIIGSELzJHkC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extra Credit"
      ],
      "metadata": {
        "id": "Ffbem5p4OYjT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Improve the UNet Architecture for time-conditional generation\n",
        "For ease of explanation and implementation, our UNet architecture above is pretty simple. Modify the UNet (e.g. with skip connections) such that it can fit better during training and sample even better results."
      ],
      "metadata": {
        "id": "RyDbefsCOmqX"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5XXU-QbvOn-_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implement Rectified Flow\n",
        "- Implement [rectified flow](https://arxiv.org/abs/2209.03003), which is the state of art diffusion model.\n",
        "- You can reference any code on github, but your implementation needs to follow the same code structure as our DDPM implementation.\n",
        "- In other words, the code change required should be minimal: only changing the forward and sample functions."
      ],
      "metadata": {
        "id": "6U1ibLs4Ooax"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PfA8WCuTOrFc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generating a PDF for CMSX\n",
        "\n",
        "You can just use `File > Print` to get a pdf of this page. Please double check that no outputs are cutoff!"
      ],
      "metadata": {
        "id": "3ZfKPAsqLNkj"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "cs180-proj5",
      "language": "python",
      "name": "cs180-proj5"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}